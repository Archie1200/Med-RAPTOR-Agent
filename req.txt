# Python 3.10+ recommended

torch>=2.0.0,<2.5.0
transformers>=4.35.0,<4.46.0
sentence-transformers>=2.2.0,<3.0.0
datasets>=2.14.0,<3.0.0

# LangChain (Modern API - LCEL compatible)
langchain>=0.1.0,<0.3.0
langchain-community>=0.0.20,<0.3.0
langchain-core>=0.1.23,<0.3.0

# RAPTOR (Hierarchical Retrieval)
raptor-rag>=1.0.0

# Vector Database
chromadb>=0.4.0,<0.6.0

# NLI Model Support (DeBERTa tokenizer fix)
tokenizers>=0.15.0,<0.20.0

# Scientific & Visualization
numpy>=1.24.0,<2.0.0
matplotlib>=3.7.0,<4.0.0
scipy>=1.11.0,<2.0.0

# NLP Utils
nltk>=3.8.0,<4.0.0
regex>=2023.0.0

# Utilities
python-dotenv>=1.0.0
tqdm>=4.65.0
pydantic>=2.0.0,<3.0.0

# Optional: Accelerate for faster GPU inference
accelerate>=0.25.0,<1.0.0

# Optional: BitsAndBytes for quantization (if needed)
# bitsandbytes>=0.41.0

# Note: If you encounter the DeBERTa tokenizer error, ensure tokenizers<0.20.0
# The key fix is using use_fast=False in AutoTokenizer.from_pretrained()